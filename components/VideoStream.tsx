'use client';

import { useEffect, useRef, useState } from 'react';
import { logger } from '@/lib/logger';

interface VideoStreamProps {
  streamUrl: string;
  protocol?: 'WEBRTC' | 'WEBRTC2' | string;
  participantName?: string;
  muted?: boolean;
  className?: string;
}

type SignallingProtocol = 'WEBRTC' | 'WEBRTC2';

function resolveSignallingProtocol(streamUrl: string, provided?: string): SignallingProtocol {
  const normalizedProvided = provided?.toUpperCase();
  if (normalizedProvided === 'WEBRTC' || normalizedProvided === 'WEBRTC2') {
    return normalizedProvided;
  }

  // –ï—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç /websocket/, —ç—Ç–æ WebRTC2
  const url = streamUrl.toLowerCase();
  if (url.includes('/websocket/')) {
    return 'WEBRTC2';
  }

  // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é WebRTC (HTTP POST)
  return 'WEBRTC';
}

/**
 * –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è WebRTC –≤–∏–¥–µ–æ-—Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏
 * –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ HTTP POST (WebRTC), —Ç–∞–∫ –∏ WebSocket (WebRTC2) signalling
 */
export default function VideoStream({
  streamUrl,
  protocol,
  participantName,
  muted = false,
  className = '',
}: VideoStreamProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const wsRef = useRef<WebSocket | null>(null);
  const pcRef = useRef<RTCPeerConnection | null>(null);
  const [isConnecting, setIsConnecting] = useState(true);
  const [error, setError] = useState<string | null>(null);

  useEffect(() => {
    if (!streamUrl) {
      setError('Stream URL –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç');
      setIsConnecting(false);
      return;
    }

    let mounted = true;
    const selectedProtocol = resolveSignallingProtocol(streamUrl, protocol);
    logger.info('[VideoStream]', `Selected signalling protocol: ${selectedProtocol}`);

    const setupWebRTCSignalling = async () => {
      try {
        logger.info('[VideoStream]', 'Setting up WebRTC HTTP POST signalling...');
        logger.info('[VideoStream]', `Stream URL: ${streamUrl.substring(0, 150)}...`);

        // –°–æ–∑–¥–∞–µ–º RTCPeerConnection
        const pc = new RTCPeerConnection({
          iceServers: [
            { urls: 'stun:stun.l.google.com:19302' },
            { urls: 'stun:stun1.l.google.com:19302' },
          ],
        });

        pcRef.current = pc;

        // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Ç—Ä–µ–∫–æ–≤
        // –í–∞–∂–Ω–æ: —Ç—Ä–µ–∫–∏ –º–æ–≥—É—Ç –ø—Ä–∏–π—Ç–∏ –¥–æ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ remote description
        let pendingTracks: MediaStream[] = [];
        pc.ontrack = (event) => {
          logger.success('[VideoStream]', `Received track: ${event.track.kind} (${event.track.id})`);
          if (event.streams && event.streams.length > 0) {
            const stream = event.streams[0];
            logger.info('[VideoStream]', `Track stream ID: ${stream.id}, tracks: ${stream.getTracks().map(t => `${t.kind}:${t.id}`).join(', ')}`);
            
            // –ï—Å–ª–∏ remote description –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–µ–∫
            if (!pc.remoteDescription) {
              logger.info('[VideoStream]', 'Track received before remote description, saving for later');
              pendingTracks.push(stream);
            } else {
              // –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–µ–∫ —Å—Ä–∞–∑—É
              if (videoRef.current) {
                videoRef.current.srcObject = stream;
                logger.success('[VideoStream]', 'Video stream applied to video element');
              }
            }
          }
        };

        // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ—Å—Ç–æ—è–Ω–∏—è ICE —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        pc.oniceconnectionstatechange = () => {
          logger.info('[VideoStream]', `ICE connection state: ${pc.iceConnectionState}`);
          if (pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed') {
            if (mounted) {
              logger.success('[VideoStream]', 'ICE connection established');
              setIsConnecting(false);
            }
          } else if (pc.iceConnectionState === 'failed') {
            if (mounted) {
              logger.error('[VideoStream]', 'ICE connection failed');
              setError('–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ');
              setIsConnecting(false);
            }
          } else if (pc.iceConnectionState === 'disconnected') {
            if (mounted) {
              logger.warn('[VideoStream]', 'ICE connection disconnected');
              setError('–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–æ');
            }
          }
        };

        // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        pc.onconnectionstatechange = () => {
          logger.info('[VideoStream]', `Connection state: ${pc.connectionState}`);
        };

        // –°–æ–±–∏—Ä–∞–µ–º ICE –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
        const candidates: RTCIceCandidateInit[] = [];
        pc.onicecandidate = (event) => {
          if (event.candidate) {
            candidates.push({
              candidate: event.candidate.candidate,
              sdpMLineIndex: event.candidate.sdpMLineIndex,
              sdpMid: event.candidate.sdpMid,
            });
          } else {
            logger.info('[VideoStream]', `ICE gathering complete. Total candidates: ${candidates.length}`);
          }
        };

        // –°–æ–∑–¥–∞–µ–º offer
        logger.info('[VideoStream]', 'Creating offer...');
        const offer = await pc.createOffer({ 
          offerToReceiveAudio: true, 
          offerToReceiveVideo: true 
        });
        await pc.setLocalDescription(offer);
        logger.success('[VideoStream]', 'Local description set');

        // –ñ–¥–µ–º —Å–±–æ—Ä–∞ ICE –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        // –°–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: —Å–æ–±–∏—Ä–∞–µ–º –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–ª–∏ —Ç–∞–π–º–∞—É—Ç–∞
        await new Promise((resolve) => {
          const checkInterval = setInterval(() => {
            if (pc.iceGatheringState === 'complete') {
              clearInterval(checkInterval);
              resolve(null);
            }
          }, 100);
          // –¢–∞–π–º–∞—É—Ç 3 —Å–µ–∫—É–Ω–¥—ã (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)
          setTimeout(() => {
            clearInterval(checkInterval);
            resolve(null);
          }, 3000);
        });

        logger.info('[VideoStream]', `Collected ${candidates.length} ICE candidates`);

        // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º URL –∏–∑ WebSocket —Ñ–æ—Ä–º–∞—Ç–∞ –≤ HTTP POST —Ñ–æ—Ä–º–∞—Ç
        // –°–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: /websocket/media/proxy/api/signalling/... -> /api/rs/media/proxy/media/...
        let httpSignallingUrl = streamUrl;
        
        // –ï—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç /websocket/, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ–≥–æ
        if (httpSignallingUrl.includes('/websocket/media/proxy/api/signalling/')) {
          // –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
          const urlMatch = httpSignallingUrl.match(/\/websocket\/media\/proxy\/api\/signalling\/([^?]+)(\?.*)?/);
          if (urlMatch) {
            const streamId = urlMatch[1];
            const queryString = urlMatch[2] || '';
            
            // –ü–∞—Ä—Å–∏–º query –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —É–±–∏—Ä–∞–µ–º signature (–æ–Ω –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è WebSocket)
            const urlObj = new URL(`http://dummy${queryString}`);
            const params = new URLSearchParams();
            
            // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (server –∏ –¥—Ä—É–≥–∏–µ, –∫—Ä–æ–º–µ signature)
            urlObj.searchParams.forEach((value, key) => {
              if (key !== 'signature') {
                params.set(key, value);
              }
            });
            
            const queryParams = params.toString() ? `?${params.toString()}` : '';
            
            // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç /api/rs/media/proxy/media/{id}_callParticipant{params}
            // –°–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–∏–º–µ—Ä—É –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: /api/rs/media/proxy/media/9c437e9c-8828-45f0-a12c-7451fe733776_callParticipant?server=...
            httpSignallingUrl = `/api/rs/media/proxy/media/${streamId}_callParticipant${queryParams}`;
            logger.info('[VideoStream]', `Converted WebSocket URL to HTTP format: ${httpSignallingUrl.substring(0, 150)}...`);
          } else {
            // Fallback: –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ–º /websocket/
            httpSignallingUrl = httpSignallingUrl.replace('/websocket/', '/');
            logger.info('[VideoStream]', `Fallback conversion: ${httpSignallingUrl.substring(0, 150)}...`);
          }
        } else if (httpSignallingUrl.includes('/api/rs/media/proxy/media/')) {
          logger.info('[VideoStream]', 'URL already in HTTP format');
        }

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—à API proxy –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ signalling –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –±—ç–∫–µ–Ω–¥
        // –§–æ—Ä–º–∞—Ç —Å–æ–≥–ª–∞—Å–Ω–æ OpenAPI: { sdp, content, candidates }
        const proxyUrl = `/api/media/signalling?path=${encodeURIComponent(httpSignallingUrl)}`;

        const signallingMessage = {
          sdp: pc.localDescription?.sdp,
          content: 'PRIMARY',
          candidates: candidates,
        };

        logger.info('[VideoStream]', `Sending HTTP POST via proxy to: ${httpSignallingUrl.substring(0, 100)}...`);

        const response = await fetch(proxyUrl, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Session': localStorage.getItem('session_id') || '',
          },
          body: JSON.stringify(signallingMessage),
        });

        if (!response.ok) {
          const errorText = await response.text();
          logger.error('[VideoStream]', `HTTP ${response.status}: ${errorText}`);
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }

        logger.success('[VideoStream]', 'HTTP POST successful, reading streaming response...');

        // –ß–∏—Ç–∞–µ–º –æ—Ç–≤–µ—Ç –ø–æ—Ç–æ–∫–æ–º (SDP answer –∏ candidates)
        // –°–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç SDP answer, –∑–∞—Ç–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –ø–æ –æ–¥–Ω–æ–º—É
        const reader = response.body?.getReader();
        const decoder = new TextDecoder();
        let buffer = '';

        if (!reader) {
          throw new Error('Response body is not readable');
        }

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          buffer += decoder.decode(value, { stream: true });
          
          // –ü–∞—Ä—Å–∏–º JSON –æ–±—ä–µ–∫—Ç—ã –∏–∑ –±—É—Ñ–µ—Ä–∞ (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - –æ—Ç–¥–µ–ª—å–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç)
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            if (line.trim()) {
              try {
                const data = JSON.parse(line);
                // Received from server

                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º SDP answer
                if (data.sdp && typeof data.sdp === 'string') {
                  logger.success('[VideoStream]', 'Received SDP answer from server');
                  try {
                    await pc.setRemoteDescription(new RTCSessionDescription({
                      type: 'answer',
                      sdp: data.sdp,
                    }));
                    logger.success('[VideoStream]', 'Remote description set successfully');
                    
                    // –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã –¥–æ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ remote description
                    if (pendingTracks.length > 0 && videoRef.current) {
                      logger.info('[VideoStream]', `Applying ${pendingTracks.length} pending track(s)`);
                      videoRef.current.srcObject = pendingTracks[0];
                      pendingTracks = [];
                    }
                  } catch (sdpErr: any) {
                    logger.error('[VideoStream]', 'Error setting remote description:', sdpErr);
                    throw sdpErr;
                  }
                }

                // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ICE –∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–ø—Ä–∏—Ö–æ–¥—è—Ç –ø–æ –æ–¥–Ω–æ–º—É)
                // –§–æ—Ä–º–∞—Ç: { candidate: { sdpMLineIndex, sdpMid, candidate } }
                if (data.candidate) {
                  // Received ICE candidate from server
                  try {
                    await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
                    // ICE candidate added successfully
                  } catch (candErr: any) {
                    logger.warn('[VideoStream]', 'Error adding ICE candidate:', candErr);
                    // –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                  }
                }
              } catch (parseErr: any) {
                logger.warn('[VideoStream]', 'Failed to parse line:', line, parseErr);
              }
            }
          }
        }

        // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä–µ
        if (buffer.trim()) {
          try {
            const data = JSON.parse(buffer);
            if (data.sdp) {
              await pc.setRemoteDescription(new RTCSessionDescription({
                type: 'answer',
                sdp: data.sdp,
              }));
            }
            if (data.candidate) {
              await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
            }
          } catch (parseErr) {
            logger.warn('[VideoStream]', 'Failed to parse remaining buffer:', buffer);
          }
        }

        logger.success('[VideoStream]', 'HTTP signalling completed, connection established');

      } catch (err: any) {
        logger.error('[VideoStream]', 'WebRTC signalling error:', err);
        if (mounted) {
          setError(err.message || '–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è');
          setIsConnecting(false);
        }
      }
    };

    const setupWebSocketSignalling = async () => {
      let pendingTracks: MediaStream[] = [];

      try {
        logger.info('[VideoStream]', `Connecting to ${participantName || 'stream'}...`);
        logger.info('[VideoStream]', 'Using WebSocket signalling (WebRTC2)');

        const pc = new RTCPeerConnection({
          iceServers: [
            { urls: 'stun:stun.l.google.com:19302' },
            { urls: 'stun:stun1.l.google.com:19302' },
          ],
        });

        pcRef.current = pc;

        pc.ontrack = (event) => {
          logger.success('[VideoStream]', `Received track: ${event.track.kind} (id: ${event.track.id})`);
          logger.info('[VideoStream]', `Track details:`, {
            kind: event.track.kind,
            id: event.track.id,
            enabled: event.track.enabled,
            readyState: event.track.readyState,
            streamsCount: event.streams.length,
            hasRemoteDescription: !!pc.remoteDescription,
          });
          
          if (event.streams && event.streams.length > 0) {
            const stream = event.streams[0];
            logger.info('[VideoStream]', `Track stream ID: ${stream.id}, tracks: ${stream.getTracks().map(t => `${t.kind}:${t.id}`).join(', ')}`);
            
            // –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–µ–∫ –∫ video —ç–ª–µ–º–µ–Ω—Ç—É
            if (videoRef.current) {
              videoRef.current.srcObject = stream;
              logger.success('[VideoStream]', 'Video stream applied to video element');
              
              // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ video —ç–ª–µ–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—é
              videoRef.current.onloadedmetadata = async () => {
                logger.success('[VideoStream]', 'Video metadata loaded');
                if (mounted) {
                  setIsConnecting(false);
                }
                // –Ø–≤–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º play() –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                if (videoRef.current) {
                  try {
                    await videoRef.current.play();
                    logger.success('[VideoStream]', 'Video play() called after metadata loaded');
                  } catch (err: any) {
                    logger.warn('[VideoStream]', 'Video play() failed after metadata (may be blocked):', err.message);
                  }
                }
              };
              
              videoRef.current.oncanplay = async () => {
                logger.success('[VideoStream]', 'Video can play (from ontrack handler)');
                // –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ canPlay
                if (videoRef.current && videoRef.current.paused) {
                  try {
                    await videoRef.current.play();
                    logger.success('[VideoStream]', 'Video play() called on canPlay (from ontrack handler)');
                  } catch (err: any) {
                    logger.warn('[VideoStream]', 'Video play() failed on canPlay (from ontrack handler):', err.message);
                  }
                }
              };
              
              videoRef.current.onplay = () => {
                logger.success('[VideoStream]', 'Video started playing (from ontrack handler)');
              };
              
              videoRef.current.onplaying = () => {
                logger.success('[VideoStream]', 'Video is now playing (from ontrack handler)');
              };
              
              videoRef.current.onerror = (err) => {
                logger.error('[VideoStream]', 'Video element error:', err);
              };
            } else {
              logger.warn('[VideoStream]', 'Video ref is null, storing track');
              pendingTracks.push(stream);
            }
          }
        };

        pc.oniceconnectionstatechange = () => {
          logger.info('[VideoStream]', `ICE connection state: ${pc.iceConnectionState}`);
          logger.info('[VideoStream]', 'Full connection state:', {
            iceConnectionState: pc.iceConnectionState,
            connectionState: pc.connectionState,
            signalingState: pc.signalingState,
            iceGatheringState: pc.iceGatheringState,
          });
          
          if (pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed') {
            if (mounted) {
              logger.success('[VideoStream]', 'ICE connection established');
              setIsConnecting(false);
              
              // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç—Ä–µ–∫–∏
              if (pc.getReceivers().length > 0) {
                logger.info('[VideoStream]', `Active receivers: ${pc.getReceivers().length}`);
                pc.getReceivers().forEach((receiver, index) => {
                  logger.info('[VideoStream]', `Receiver ${index}:`, {
                    track: receiver.track ? `${receiver.track.kind} (${receiver.track.id})` : 'no track',
                    transport: receiver.transport ? 'has transport' : 'no transport',
                  });
                });
              } else {
                logger.warn('[VideoStream]', 'No receivers found after connection');
              }
            }
          } else if (pc.iceConnectionState === 'failed') {
            if (mounted) {
              logger.error('[VideoStream]', 'ICE connection failed');
              setError('–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ');
              setIsConnecting(false);
            }
          }
        };

        pc.onconnectionstatechange = () => {
          logger.info('[VideoStream]', `Connection state: ${pc.connectionState}`);
        };

        const buildWebSocketUrl = () => {
          const ensureContentType = (rawUrl: string) => {
            const urlObj = new URL(rawUrl);
            if (!urlObj.searchParams.has('contentType')) {
              urlObj.searchParams.set('contentType', 'CONFERENCE_PARTICIPANT_PRIMARY');
            }
            const sessionId = typeof window !== 'undefined' ? localStorage.getItem('session_id') : null;
            if (sessionId && !urlObj.searchParams.has('Session')) {
              urlObj.searchParams.set('Session', sessionId);
            }
            return urlObj.toString();
          };

          const trimmedUrl = streamUrl.trim();
          if (trimmedUrl.startsWith('ws://') || trimmedUrl.startsWith('wss://')) {
            return ensureContentType(trimmedUrl);
          }

          if (trimmedUrl.startsWith('http://') || trimmedUrl.startsWith('https://')) {
            const parsed = new URL(trimmedUrl);
            parsed.protocol = parsed.protocol === 'https:' ? 'wss:' : 'ws:';
            return ensureContentType(parsed.toString());
          }

          const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
          const hostFromEnv = process.env.NEXT_PUBLIC_WS_HOST;
          const host = hostFromEnv && hostFromEnv.length > 0 ? hostFromEnv : window.location.host;
          const normalizedPath = trimmedUrl.startsWith('/') ? trimmedUrl : `/${trimmedUrl}`;
          return ensureContentType(`${wsProtocol}//${host}${normalizedPath}`);
        };

        const wsUrl = buildWebSocketUrl();
        logger.info('[VideoStream]', `Connecting to WebSocket: ${wsUrl.substring(0, 150)}...`);
        const ws = new WebSocket(wsUrl);
        wsRef.current = ws;

        const candidates: RTCIceCandidateInit[] = [];
        let iceGatheringComplete = false;
        let offerSent = false;

        pc.onicecandidate = (event) => {
          if (event.candidate) {
            candidates.push({
              candidate: event.candidate.candidate,
              sdpMLineIndex: event.candidate.sdpMLineIndex,
              sdpMid: event.candidate.sdpMid,
            });
          } else {
            iceGatheringComplete = true;
            logger.info('[VideoStream]', `ICE gathering complete. Total candidates: ${candidates.length}`);
            if (offerSent && ws.readyState === WebSocket.OPEN) {
              if (candidates.length > 0) {
                logger.info('[VideoStream]', 'Sending remaining ICE candidates');
                ws.send(JSON.stringify({ candidates: candidates }));
              }
            }
          }
        };

        ws.onopen = async () => {
          logger.success('[VideoStream]', 'WebSocket connected');
          
          try {
            logger.info('[VideoStream]', 'Creating offer for WebRTC2...');
            
            const offer = await pc.createOffer({ 
              offerToReceiveAudio: true, 
              offerToReceiveVideo: true 
            });
            await pc.setLocalDescription(offer);
            logger.success('[VideoStream]', 'Local description set');
            
            const waitForIce = new Promise<void>((resolve) => {
              const checkInterval = setInterval(() => {
                if (iceGatheringComplete || pc.iceGatheringState === 'complete') {
                  clearInterval(checkInterval);
                  resolve();
                }
              }, 100);
              setTimeout(() => {
                clearInterval(checkInterval);
                resolve();
              }, 3000);
            });
            
            await waitForIce;
            logger.info('[VideoStream]', `Collected ${candidates.length} ICE candidates`);
            
            // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º offer —Å SDP –∏ candidates
            // –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã, –Ω–∞—á–∏–Ω–∞—è —Å –ø—Ä–æ—Å—Ç–æ–≥–æ
            const offerMessage = {
              sdp: offer.sdp,
              content: 'PRIMARY',
              candidates: candidates,
            };
            
            logger.info('[VideoStream]', 'Sending offer to server');
            
            ws.send(JSON.stringify(offerMessage));
            offerSent = true;
          } catch (err: any) {
            logger.error('[VideoStream]', 'Error creating/sending offer:', err);
            if (mounted) {
              setError(`–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è offer: ${err.message}`);
              setIsConnecting(false);
            }
          }
        };

        ws.onmessage = async (event) => {
          try {
            logger.info('[VideoStream]', 'üì® Received message from server');
            
            let data: any;
            try {
              data = JSON.parse(event.data);
            } catch (parseErr) {
              logger.warn('[VideoStream]', 'Failed to parse message as JSON:', event.data);
              return;
            }
            
            // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º SDP answer (–º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–ª—è—Ö)
            let sdpAnswer: string | null = null;
            if (data.sdp && typeof data.sdp === 'string') {
              sdpAnswer = data.sdp;
            } else if (data.sessionDescription && typeof data.sessionDescription === 'string') {
              sdpAnswer = data.sessionDescription;
            } else if (data.answer && typeof data.answer === 'string') {
              sdpAnswer = data.answer;
            }
            
            if (sdpAnswer) {
              logger.success('[VideoStream]', 'Received SDP answer from server');
              try {
                await pc.setRemoteDescription(new RTCSessionDescription({
                  type: 'answer',
                  sdp: sdpAnswer,
                }));
                logger.success('[VideoStream]', 'Remote description set successfully');
                logger.info('[VideoStream]', 'Connection state after setting remote description:', {
                  iceConnectionState: pc.iceConnectionState,
                  connectionState: pc.connectionState,
                  signalingState: pc.signalingState,
                  receiversCount: pc.getReceivers().length,
                });
                
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–µ–∫–∏ –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ remote description
                if (pc.getReceivers().length > 0) {
                  logger.info('[VideoStream]', `Found ${pc.getReceivers().length} receiver(s) after setting remote description`);
                  pc.getReceivers().forEach((receiver, index) => {
                    if (receiver.track) {
                      logger.info('[VideoStream]', `Receiver ${index} track: ${receiver.track.kind} (${receiver.track.id}), enabled: ${receiver.track.enabled}`);
                    }
                  });
                }
                
                // –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã –¥–æ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ remote description
                if (pendingTracks.length > 0 && videoRef.current) {
                  logger.info('[VideoStream]', `Applying ${pendingTracks.length} pending track(s)`);
                  videoRef.current.srcObject = pendingTracks[0];
                  pendingTracks = [];
                } else if (videoRef.current && !videoRef.current.srcObject) {
                  // –ï—Å–ª–∏ —Ç—Ä–µ–∫–∏ –µ—â–µ –Ω–µ –ø—Ä–∏—à–ª–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É
                  setTimeout(() => {
                    if (pc.getReceivers().length > 0 && videoRef.current && !videoRef.current.srcObject) {
                      logger.info('[VideoStream]', 'Attempting to get stream from receivers');
                      const receivers = pc.getReceivers();
                      for (const receiver of receivers) {
                        if (receiver.track && receiver.track.kind === 'video') {
                          const stream = new MediaStream([receiver.track]);
                          videoRef.current.srcObject = stream;
                          logger.success('[VideoStream]', 'Created stream from receiver track');
                          break;
                        }
                      }
                    }
                  }, 500);
                }
              } catch (sdpErr: any) {
                logger.error('[VideoStream]', 'Error setting remote description:', sdpErr);
                throw sdpErr;
              }
            }

            // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ICE –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
            if (data.candidates && Array.isArray(data.candidates)) {
              logger.info('[VideoStream]', `Received ${data.candidates.length} ICE candidates`);
              for (const cand of data.candidates) {
                try {
                  await pc.addIceCandidate(new RTCIceCandidate(cand));
                } catch (candErr: any) {
                  logger.warn('[VideoStream]', 'Error adding ICE candidate:', candErr);
                }
              }
            } else if (data.candidate) {
              try {
                await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
              } catch (candErr: any) {
                logger.warn('[VideoStream]', 'Error adding ICE candidate:', candErr);
              }
            }
            
            // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è
          } catch (err: any) {
            logger.error('[VideoStream]', 'Error processing message:', err);
            if (mounted && !error) {
              setError(`–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: ${err.message}`);
            }
          }
        };

        ws.onerror = (error) => {
          logger.error('[VideoStream]', 'WebSocket error:', error);
          if (mounted) {
            setError('–û—à–∏–±–∫–∞ WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è');
            setIsConnecting(false);
          }
        };

        ws.onclose = (event) => {
          logger.info('[VideoStream]', `WebSocket closed. Code: ${event.code}, Reason: ${event.reason}`);
          if (mounted && event.code !== 1000) {
            setError(`WebSocket –∑–∞–∫—Ä—ã—Ç: ${event.reason || '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞'}`);
            setIsConnecting(false);
          }
        };

      } catch (err: any) {
        logger.error('[VideoStream]', 'Setup error:', err);
        if (mounted) {
          setError(err.message || '–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è');
          setIsConnecting(false);
        }
      }
    };

    if (selectedProtocol === 'WEBRTC2') {
      setupWebSocketSignalling();
    } else {
      setupWebRTCSignalling();
    }

    // Cleanup
    return () => {
      mounted = false;
      logger.cleanup('[VideoStream]', 'Closing connections');
      
      if (wsRef.current) {
        wsRef.current.close();
        wsRef.current = null;
      }
      
      if (pcRef.current) {
        pcRef.current.close();
        pcRef.current = null;
      }
    };
  }, [streamUrl, participantName, protocol]);

  return (
    <div className={`relative bg-gray-900 rounded-lg overflow-hidden ${className}`}>
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted={muted}
        className="w-full h-full object-cover"
        onLoadedMetadata={async () => {
          // –Ø–≤–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º play() –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
          if (videoRef.current) {
            try {
              await videoRef.current.play();
            } catch (err: any) {
              // –ï—Å–ª–∏ –∞–≤—Ç–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Ä—É—á–Ω—É—é
            }
          }
        }}
        onCanPlay={async () => {
          // –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ canPlay
          if (videoRef.current && videoRef.current.paused) {
            try {
              await videoRef.current.play();
            } catch (err: any) {
              // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∞–≤—Ç–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
            }
          }
        }}
        onPlay={() => {
          logger.success('[VideoStream]', 'Video started playing');
        }}
        onPause={() => {
          logger.info('[VideoStream]', 'Video paused');
        }}
        onPlaying={() => {
          logger.success('[VideoStream]', 'Video is now playing');
        }}
        onError={(e) => {
          logger.error('[VideoStream]', 'Video element error:', e);
        }}
      />
      
      {/* Overlay –¥–ª—è –∏–º–µ–Ω–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞ */}
      {participantName && (
        <div className="absolute bottom-2 left-2 bg-black bg-opacity-70 text-white text-sm px-3 py-1 rounded">
          {participantName}
        </div>
      )}

      {/* –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ */}
      {isConnecting && (
        <div className="absolute inset-0 flex items-center justify-center bg-gray-900">
          <div className="text-center">
            <div className="animate-spin rounded-full h-10 w-10 border-b-2 border-white mx-auto mb-2"></div>
            <p className="text-white text-sm">–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...</p>
          </div>
        </div>
      )}

      {/* –û—à–∏–±–∫–∞ */}
      {error && (
        <div className="absolute inset-0 flex items-center justify-center bg-gray-900">
          <div className="text-center px-4">
            <svg className="w-12 h-12 text-red-500 mx-auto mb-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
            </svg>
            <p className="text-white text-sm">{error}</p>
          </div>
        </div>
      )}
    </div>
  );
}
